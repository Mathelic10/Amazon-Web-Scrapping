{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon Web Scrapping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIDq4lGOyfjD"
      },
      "source": [
        "link: https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFRm8WRbDcLX"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrKsrVayEHsp"
      },
      "source": [
        "HEADER = ({'User-Agent':\n",
        "           'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36 Edg/96.0.1054.29'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R63CWMIGy6__"
      },
      "source": [
        "url = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\"\n",
        "page = requests.get(url, headers = HEADER)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews = soup.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list1 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('a', class_ = 'a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold').text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list1.append(tuple(row_set))\n",
        "list1\n",
        "df1 = pd.DataFrame(list1,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eqRHNe48iAI"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=2\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('a', class_ = 'a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold').text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "list2\n",
        "df2 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kf7xRNs8h9E"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=3\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('a', class_ = 'a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold').text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "list2\n",
        "df3 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIucfAx_8h6m"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_ \\\n",
        "        next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=4\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('a', class_ = 'a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold').text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "list2\n",
        "df4 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC0Q2uecBwyp"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_ \\\n",
        "        next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=5\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('a', class_ = 'a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold').text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "list2\n",
        "df5 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0JcLJWqB97O"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_ \\\n",
        "        next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=5\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('a', class_ = 'a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold').text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "list2\n",
        "df5 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_IkZ9gXCDgl"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_ \\\n",
        "        next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=6\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('a', class_ = 'a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold').text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "list2\n",
        "df6 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbGKyE2NCJAs"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_ \\\n",
        "        next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=7\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('a', class_ = 'a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold').text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "list2\n",
        "df7 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vWNfQjGCgUE"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_ \\\n",
        "        next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=8\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('a', class_ = 'a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold').text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "list2\n",
        "df8 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb8JSKYsClZ8"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_ \\\n",
        "        next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=9\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('a', class_ = 'a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold').text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "list2\n",
        "df9 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdv2SXYXCph6"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_ \\\n",
        "        next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=11\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('span', class_ = 'a-size-base review-title a-color-base review-title-content a-text-bold').span.text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "\n",
        "df11 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJoBZcWiCxA_"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_ \\\n",
        "        next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=12\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('span', class_ = 'a-size-base review-title a-color-base review-title-content a-text-bold').span.text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "list2\n",
        "df12 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZzbQ6rxFmPM"
      },
      "source": [
        "url2 = \"https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-Tensor/product-reviews/9352139054/ref=cm_cr_arp_d_paging_btm_ \\\n",
        "        next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=13\"\n",
        "page2 = requests.get(url2, headers = HEADER)\n",
        "soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
        "# pointing to all the review divisions \n",
        "reviews2 = soup2.find_all('div', class_ = \"a-section review aok-relative\")\n",
        "list2 = []\n",
        "# extracting the required texts from each review\n",
        "for review in reviews2:\n",
        "  reviewer = review.find('span', class_ = 'a-profile-name').text\n",
        "  rating = review.find('span', class_ = 'a-icon-alt').text\n",
        "  place_date = review.find('span', class_ = 'a-size-base a-color-secondary review-date').text\n",
        "  review_short = review.find('span', class_ = 'a-size-base review-title a-color-base review-title-content a-text-bold').span.text.strip()\n",
        "  review_content = review.find('span', class_ = 'a-size-base review-text review-text-content').text.strip()\n",
        "  row_set = (reviewer, rating, place_date, review_short, review_content)\n",
        "  list2.append(tuple(row_set))\n",
        "df13 = pd.DataFrame(list2,  columns = ['reviewer', \"stars\", 'place_date', 'review_short', 'review_content'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aGiqg0IhIxKA",
        "outputId": "36475d44-dda6-49ee-eb96-34b7844a1061"
      },
      "source": [
        "df_oreilly = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df11,df12,df13], ignore_index=True)\n",
        "df_oreilly.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewer</th>\n",
              "      <th>stars</th>\n",
              "      <th>place_date</th>\n",
              "      <th>review_short</th>\n",
              "      <th>review_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mr. Happy</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>Reviewed in India on 2 November 2019</td>\n",
              "      <td>Comprehensive treatment of the whole gamut of ML</td>\n",
              "      <td>If you are a practitioner of ML, I'd suggest y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>YK</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>Reviewed in India on 27 December 2019</td>\n",
              "      <td>A very good practical book on Machine Learning</td>\n",
              "      <td>I got this book yesterday and I already finish...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Xenon</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>Reviewed in India on 31 December 2019</td>\n",
              "      <td>Must have technical guide for enthusiasts and ...</td>\n",
              "      <td>I had my eye on this since the author publishe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SS Ray</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>Reviewed in India on 5 September 2020</td>\n",
              "      <td>Wonderful book with clear explanations on the ...</td>\n",
              "      <td>This is one of the best books I have read in m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vinay Verma</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>Reviewed in India on 19 October 2020</td>\n",
              "      <td>INDIAN Version is Cheaper, Other one is twice ...</td>\n",
              "      <td>So Finally I got the book at around 2000Rs. Th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      reviewer  ...                                     review_content\n",
              "0    Mr. Happy  ...  If you are a practitioner of ML, I'd suggest y...\n",
              "1           YK  ...  I got this book yesterday and I already finish...\n",
              "2        Xenon  ...  I had my eye on this since the author publishe...\n",
              "3       SS Ray  ...  This is one of the best books I have read in m...\n",
              "4  Vinay Verma  ...  So Finally I got the book at around 2000Rs. Th...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ1XakJhMzll"
      },
      "source": [
        "#cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1yOybmmMmXX",
        "outputId": "564a88a5-ca32-4fec-c5fa-01d80d6d5254"
      },
      "source": [
        "df_oreilly = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df11,df12,df13], ignore_index=True)\n",
        "df_oreilly[['place','date']] = df_oreilly['place_date'].str.split('on', expand = True)\n",
        "df_oreilly.drop(columns=['place_date'], inplace = True)\n",
        "\n",
        "df_oreilly['stars'] = df_oreilly['stars'].str.replace('out of 5 stars','')\n",
        "df_oreilly['place'] = df_oreilly['place'].str.replace('Reviewed in ','')\n",
        "\n",
        "df_oreilly['stars'] = df_oreilly['stars'].astype('float')\n",
        "df_oreilly['date'] = pd.to_datetime(df_oreilly['date'])\n",
        "\n",
        "df_oreilly.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 114 entries, 0 to 113\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   reviewer        114 non-null    object        \n",
            " 1   stars           114 non-null    float64       \n",
            " 2   review_short    114 non-null    object        \n",
            " 3   review_content  114 non-null    object        \n",
            " 4   place           114 non-null    object        \n",
            " 5   date            114 non-null    datetime64[ns]\n",
            "dtypes: datetime64[ns](1), float64(1), object(4)\n",
            "memory usage: 5.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7dSZuLgSMxOn",
        "outputId": "2cf9e86a-6ae0-4155-dce6-1f28f2303466"
      },
      "source": [
        "df_oreilly.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewer</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_short</th>\n",
              "      <th>review_content</th>\n",
              "      <th>place</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mr. Happy</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Comprehensive treatment of the whole gamut of ML</td>\n",
              "      <td>If you are a practitioner of ML, I'd suggest y...</td>\n",
              "      <td>India</td>\n",
              "      <td>2019-11-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>YK</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A very good practical book on Machine Learning</td>\n",
              "      <td>I got this book yesterday and I already finish...</td>\n",
              "      <td>India</td>\n",
              "      <td>2019-12-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Xenon</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Must have technical guide for enthusiasts and ...</td>\n",
              "      <td>I had my eye on this since the author publishe...</td>\n",
              "      <td>India</td>\n",
              "      <td>2019-12-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SS Ray</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Wonderful book with clear explanations on the ...</td>\n",
              "      <td>This is one of the best books I have read in m...</td>\n",
              "      <td>India</td>\n",
              "      <td>2020-09-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vinay Verma</td>\n",
              "      <td>5.0</td>\n",
              "      <td>INDIAN Version is Cheaper, Other one is twice ...</td>\n",
              "      <td>So Finally I got the book at around 2000Rs. Th...</td>\n",
              "      <td>India</td>\n",
              "      <td>2020-10-19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      reviewer  stars  ...   place       date\n",
              "0    Mr. Happy    5.0  ...  India  2019-11-02\n",
              "1           YK    5.0  ...  India  2019-12-27\n",
              "2        Xenon    5.0  ...  India  2019-12-31\n",
              "3       SS Ray    5.0  ...  India  2020-09-05\n",
              "4  Vinay Verma    5.0  ...  India  2020-10-19\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}